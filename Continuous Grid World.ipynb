{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "59b47232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3f356488",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Continuous_gridWorld:\n",
    "    def __init__(self, blocked_center):\n",
    "        self.yaxis = 100\n",
    "        self.xaxis = 100\n",
    "        self.blocked_center = blocked_center\n",
    "        self.initial_state = [(3, 3), (3, 4), (3, 5), (4, 3), (4, 4), (4, 5), (5, 3), (5, 4), (5, 5)]\n",
    "        self.state = self.initial_state\n",
    "\n",
    "    def create_blocked(self):\n",
    "        self.blocked_list = []\n",
    "        for i in self.blocked_center:\n",
    "            for j in range(i[0]-6, i[0] + 5):\n",
    "                for k in range(i[1] - 6, i[1] + 5):\n",
    "                    if k < self.xaxis or j < self.yaxis or k >= 0 or j >= 0:\n",
    "                        if k not in self.blocked_list:\n",
    "                            self.blocked_list.append((j, k))\n",
    "        return self.blocked_list\n",
    "\n",
    "    def show_world(self):\n",
    "        grid = np.zeros([self.xaxis, self.yaxis])\n",
    "        for i in self.blocked_list:\n",
    "            grid[i[0]][i[1]] = 1\n",
    "        return grid\n",
    "\n",
    "    def cost_movement(self, state):\n",
    "        cost = 0\n",
    "        for i in state:\n",
    "            if i in self.blocked_list:\n",
    "                cost += 1000\n",
    "            elif i in self.terminal_state:\n",
    "                cost += 0\n",
    "            else:\n",
    "                cost += 1\n",
    "        return cost\n",
    "\n",
    "    def transition_function(self, action):\n",
    "        if action == 'L':\n",
    "            nxtState = [(s[0] - 10, s[1])\n",
    "                        for s in self.state if s[0] - 10 >= 0]\n",
    "        elif action == 'R':\n",
    "            nxtState = [(s[0] + 10, s[1])\n",
    "                        for s in self.state if s[0] + 10 <= self.xaxis - 1]\n",
    "        elif action == 'U':\n",
    "            nxtState = [(s[0], s[1] + 10)\n",
    "                        for s in self.state if s[1] + 10 <= self.yaxis - 1]\n",
    "        else:\n",
    "            nxtState = [(s[0], s[1] - 10)\n",
    "                        for s in self.state if s[1] - 10 >= 0]\n",
    "        n = 0\n",
    "        for s in self.state:\n",
    "            if (s[0] >= 10) and (s[0] <= self.xaxis - 10):\n",
    "                if (s[1] >= 0) and (s[1] <= self.yaxis - 1):\n",
    "                    n = 1\n",
    "                    break\n",
    "        if n == 0:\n",
    "            return self.state\n",
    "        elif n == 1:\n",
    "            return nxtState\n",
    "\n",
    "    def terminal_state_create(self):\n",
    "        self.terminal_state = []\n",
    "        for i in range(20):\n",
    "            for j in range(20):\n",
    "                self.terminal_state.append([i, j])\n",
    "        return self.terminal_state\n",
    "\n",
    "    def episode_break(self, state):\n",
    "        \n",
    "        for i in self.terminal_state:\n",
    "            if state == i:\n",
    "                return True\n",
    "        for i in self.blocked_list:\n",
    "            if state == i:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self):\n",
    "        # world = Continuous_gridWorld()\n",
    "        self.actions = ['L', 'R', 'U', 'D']\n",
    "\n",
    "        self.qtable = []\n",
    "        for q in range(0, 10):\n",
    "            self.qtable.append([])\n",
    "            for p in range(0, 10):\n",
    "                self.qtable[q].append([])\n",
    "                for a in range(4):\n",
    "                    self.qtable[q][p].append(0)\n",
    "\n",
    "    def action_selection(self, epsilon, state):\n",
    "        if random.uniform(0, 1) <= epsilon:\n",
    "            action = random.choice(self.actions)\n",
    "        else:\n",
    "            action_index = np.argmin(self.qtable[state[0]//10][state[1]//10])\n",
    "            action = self.actions[action_index]\n",
    "        return action\n",
    "\n",
    "    def q_value_update(self, currentState, nxtState, action, cost):\n",
    "        action_index = [x for x in self.actions if action == self.actions]\n",
    "        min_nxtState = np.argmin(self.qtable[nxtState[0]//10][nxtState[1]//10])\n",
    "        self.qtable[currentState[0]//10][currentState[1]//10][action[0]] += self.alpha * (\n",
    "            cost + self.gamma * min_nxtState - self.qtable[currentState[0]//10][currentState[1]//10][action[0]])\n",
    "    \n",
    "        return self.qtable[currentState[0]//10][currentState[1]//10][action]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "54d1d304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(world, Agent, alpha=0.9, gamma=0.2, episode=500, epsilon = 0.9):\n",
    "    steps_per_episode = []\n",
    "    cost_per_episode = []                      #used for storing the total cost of each episode for plotting\n",
    "    epsilon_per_episode = []\n",
    "    grid_per_episode = []\n",
    "    action_per_episode = []\n",
    "    qvalue_per_episode = []\n",
    "    state_per_episode = []\n",
    "    world.terminal_state_create()\n",
    "    world.create_blocked()\n",
    "    \n",
    "    for z in range(episode):\n",
    "        cumulative_cost = 0\n",
    "        steps = 0\n",
    "        grid_per_step = []\n",
    "            # grid_wrld = self.world.grid_wrld()\n",
    "\n",
    "        action_per_step = []\n",
    "        qvalue_per_step = []\n",
    "        cost_per_step = []\n",
    "        state_per_step = []\n",
    "        while world.episode_break(world.state[4]) == False:\n",
    "            lastState = world.state\n",
    "            \n",
    "            state_per_step.append(lastState[4])\n",
    "\n",
    "            action = Agent.action_selection(epsilon, lastState[4])\n",
    "\n",
    "            currentState = world.transition_function(action)\n",
    "            \n",
    "            per_cost = world.cost_movement(currentState)\n",
    "            print(action)\n",
    "            print(currentState)\n",
    "            x = Agent.q_value_update(lastState[4], currentState[4], action, per_cost)\n",
    "\n",
    "            cumulative_cost += per_cost\n",
    "            steps += 1\n",
    "            # grid_per_step.append(grid)\n",
    "            # action_index_per_step.append(action_index)\n",
    "            qvalue_per_step.append(x)\n",
    "            cost_per_step.append(per_cost)\n",
    "        \n",
    "        if world.episode_break() == True:\n",
    "            world.state = world.initial_state\n",
    "        \n",
    "        if z % 50 == 0:\n",
    "            epsilon *= 0.45\n",
    "\n",
    "        steps_per_episode.append(steps)\n",
    "        cost_per_episode.append(cumulative_cost)\n",
    "        epsilon_per_episode.append(epsilon)\n",
    "        # grid_per_episode.append(grid_per_step)\n",
    "        action_per_episode.append(action_per_step)\n",
    "        qvalue_per_episode.append(qvalue_per_step)\n",
    "        state_per_episode.append(state_per_step)\n",
    "\n",
    "    return cost_per_episode, state_per_episode, epsilon_per_episode, action_per_episode, qvalue_per_episode, state_per_episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1246bb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L\n",
      "[]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [82], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m world \u001b[38;5;241m=\u001b[39m Continuous_gridWorld([(\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m), (\u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m50\u001b[39m), (\u001b[38;5;241m70\u001b[39m, \u001b[38;5;241m50\u001b[39m), (\u001b[38;5;241m90\u001b[39m, \u001b[38;5;241m50\u001b[39m), (\u001b[38;5;241m60\u001b[39m,\u001b[38;5;241m65\u001b[39m), (\u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m75\u001b[39m), (\u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m85\u001b[39m), (\u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m95\u001b[39m)])\n\u001b[1;32m      2\u001b[0m Agentx \u001b[38;5;241m=\u001b[39m Agent()\n\u001b[0;32m----> 5\u001b[0m cost_per_episode, steps_per_episode, epsilon_per_episode, action_index_per_episode, qvalue_per_episode, state_per_episode \u001b[38;5;241m=\u001b[39m play(world, Agentx)\n",
      "Cell \u001b[0;32mIn [81], line 34\u001b[0m, in \u001b[0;36mplay\u001b[0;34m(world, Agent, alpha, gamma, episode, epsilon)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(action)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(currentState)\n\u001b[0;32m---> 34\u001b[0m x \u001b[38;5;241m=\u001b[39m Agent\u001b[38;5;241m.\u001b[39mq_value_update(lastState[\u001b[38;5;241m4\u001b[39m], \u001b[43mcurrentState\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m, action, per_cost)\n\u001b[1;32m     36\u001b[0m cumulative_cost \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m per_cost\n\u001b[1;32m     37\u001b[0m steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "world = Continuous_gridWorld([(50, 50), (60, 50), (70, 50), (90, 50), (60,65), (60, 75), (60, 85), (60, 95)])\n",
    "Agentx = Agent()\n",
    "\n",
    "\n",
    "cost_per_episode, steps_per_episode, epsilon_per_episode, action_index_per_episode, qvalue_per_episode, state_per_episode = play(world, Agentx)\n",
    "\n",
    "\n",
    "# using matplotlib for plotting episode in x-axis and cost in y-axis\n",
    "# fig1 = plt.figure(\"Figure1\")\n",
    "# plt.plot(cost_per_episode)\n",
    "# plt.ylim(0, 150)\n",
    "# plt.title(\"Cost per Episode\")\n",
    "# fig2 = plt.figure(\"Figure2\")\n",
    "# plt.plot(steps_per_episode)\n",
    "# plt.ylim(0, 150)\n",
    "# plt.title(\"Steps per Episode\")\n",
    "# fig3 = plt.figure(\"Figure3\")\n",
    "# plt.plot(epsilon_per_episode)\n",
    "# plt.title(\"Epsilon per Episode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05364ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "hi\n"
     ]
    }
   ],
   "source": [
    "x = [1, 2, 3]\n",
    "y = [2, 9, 1]\n",
    "\n",
    "for i in x:\n",
    "    if i in y:\n",
    "        print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d967c70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
