{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "59b47232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f356488",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from curses import flash\n",
    "\n",
    "\n",
    "class Continuous_gridWorld:\n",
    "    def __init__(self, blocked_center):\n",
    "        self.yaxis = 100\n",
    "        self.xaxis = 100\n",
    "        self.blocked_center = blocked_center\n",
    "        self.initial_state = np.array(\n",
    "            [(3, 3), (3, 4), (3, 5), (4, 3), (4, 4), (4, 5), (5, 3), (5, 4), (5, 5)])\n",
    "        self.state = self.initial_state\n",
    "\n",
    "    def create_blocked(self):\n",
    "        self.blocked_list = []\n",
    "        for i in self.blocked_center:\n",
    "            for j in range(i[0]-6, i[0] + 5):\n",
    "                for k in range(i[1] - 6, i[1] + 5):\n",
    "                    if k < self.xaxis or j < self.yaxis or k >= 0 or j >= 0:\n",
    "                        if k not in self.blocked_list:\n",
    "                            self.blocked_list.append((j, k))\n",
    "        return self.blocked_list\n",
    "\n",
    "    def show_world(self):\n",
    "        grid = np.zeros([self.xaxis, self.yaxis])\n",
    "        for i in self.blocked_list:\n",
    "            grid[i[0]][i[1]] = 1\n",
    "        return grid\n",
    "\n",
    "    def cost_movement(self, state):\n",
    "        for i in state:\n",
    "            if i in self.blocked_list:\n",
    "                cost = 1000\n",
    "            elif i in self.terminal_state:\n",
    "                cost = 0\n",
    "            else:\n",
    "                cost = 1\n",
    "        return cost\n",
    "\n",
    "    def transition_function(self, action):\n",
    "        if action == 'L':\n",
    "            nxtState = [(s[0] - 10, s[1])\n",
    "                        for s in self.state if s[0] - 10 >= 0]\n",
    "        elif action == 'R':\n",
    "            nxtState = [(s[0] + 10, s[1])\n",
    "                        for s in self.state if s[0] + 10 <= self.xaxis - 1]\n",
    "        elif action == 'U':\n",
    "            nxtState = [(s[0], s[1] + 10)\n",
    "                        for s in self.state if s[1] + 10 <= self.yaxis - 1]\n",
    "        else:\n",
    "            nxtState = [(s[0], s[1] - 10)\n",
    "                        for s in self.state if s[1] - 10 >= 0]\n",
    "\n",
    "        for s in self.state:\n",
    "            if (s[0] >= 0) and (s[0] <= self.xaxis - 1):\n",
    "                if (s[1] >= 0) and (s[1] <= self.yaxis - 1):\n",
    "                    return nxtState\n",
    "        return self.state\n",
    "\n",
    "    def terminal_state_create(self):\n",
    "        self.terminal_state = []\n",
    "        for i in range(20):\n",
    "            for j in range(20):\n",
    "                self.terminal_state.append([i, j])\n",
    "        return self.terminal_state\n",
    "\n",
    "    def episode_break(self, state):\n",
    "        \n",
    "        for i in self.terminal_state:\n",
    "            if state == i:\n",
    "                return True\n",
    "        for i in self.blocked_list:\n",
    "            if state == i:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self):\n",
    "        # world = Continuous_gridWorld()\n",
    "        self.actions = ['L', 'R', 'U', 'D']\n",
    "\n",
    "        self.qtable = []\n",
    "        for q in range(0, 10):\n",
    "            self.qtable.append([])\n",
    "            for p in range(0, 10):\n",
    "                self.qtable[q].append([])\n",
    "                for a in range(4):\n",
    "                    self.qtable[q][p].append(0)\n",
    "\n",
    "    def action_selection(self, epsilon, state):\n",
    "        if random.random <= epsilon:\n",
    "            action = random.randrange(self.actions)\n",
    "        else:\n",
    "            action_index = np.argmin(self.qtable[state[0]//10][state[1]//10])\n",
    "            action = self.actions[action_index]\n",
    "        return action\n",
    "\n",
    "    def q_value_update(self, currentState, nxtState, action, cost):\n",
    "        min_nxtState = np.argmin(self.qtable[nxtState[0]//10][nxtState[1]//10])\n",
    "        self.qtable[currentState[0]//10][currentState[1]//10][action] += self.alpha * (\n",
    "            cost + self.gamma * min_nxtState - self.qtable[currentState[0]//10][currentState[1]//10][action])\n",
    "\n",
    "def play(world, Agent, alpha=0.9, gamma=0.2, episode=500, epsilon = 0.9):\n",
    "    steps_per_episode = []\n",
    "    cost_per_episode = []                      #used for storing the total cost of each episode for plotting\n",
    "    epsilon_per_episode = []\n",
    "    grid_per_episode = []\n",
    "    action_per_episode = []\n",
    "    qvalue_per_episode = []\n",
    "    state_per_episode = []\n",
    "    world.terminal_state_create()\n",
    "    for z in range(episode):\n",
    "        cumulative_cost = 0\n",
    "        steps = 0\n",
    "        grid_per_step = []\n",
    "            # grid_wrld = self.world.grid_wrld()\n",
    "\n",
    "        action_per_step = []\n",
    "        qvalue_per_step = []\n",
    "        cost_per_step = []\n",
    "        state_per_step = []\n",
    "        while world.episode_break(world.state[4]) == False:\n",
    "            lastState = world.state\n",
    "\n",
    "            state_per_step.append(lastState)\n",
    "\n",
    "            action = Agent.action_selection(epsilon, lastState)\n",
    "\n",
    "            currentState = world.transition_function(lastState)\n",
    "\n",
    "            cost = world.cost_movement(currentState)\n",
    "\n",
    "            x = Agent.q_value_update(lastState, currentState, action, cost)\n",
    "\n",
    "            cumulative_cost += cost\n",
    "            steps += 1\n",
    "            # grid_per_step.append(grid)\n",
    "            # action_index_per_step.append(action_index)\n",
    "            qvalue_per_step.append(x)\n",
    "            cost_per_step.append(cost)\n",
    "        \n",
    "        if world.episode_break() == True:\n",
    "            world.state = world.initial_state\n",
    "        \n",
    "        if z % 50 == 0:\n",
    "            epsilon *= 0.45\n",
    "\n",
    "        steps_per_episode.append(steps)\n",
    "        cost_per_episode.append(cumulative_cost)\n",
    "        epsilon_per_episode.append(epsilon)\n",
    "        # grid_per_episode.append(grid_per_step)\n",
    "        action_per_episode.append(action_per_step)\n",
    "        qvalue_per_episode.append(qvalue_per_step)\n",
    "        state_per_episode.append(state_per_step)\n",
    "\n",
    "    return cost_per_episode, state_per_episode, epsilon_per_episode, action_per_episode, qvalue_per_episode, state_per_episode\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1246bb76",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [37], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m world \u001b[38;5;241m=\u001b[39m Continuous_gridWorld([(\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m), (\u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m50\u001b[39m), (\u001b[38;5;241m70\u001b[39m, \u001b[38;5;241m50\u001b[39m), (\u001b[38;5;241m90\u001b[39m, \u001b[38;5;241m50\u001b[39m), (\u001b[38;5;241m60\u001b[39m,\u001b[38;5;241m65\u001b[39m), (\u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m75\u001b[39m), (\u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m85\u001b[39m), (\u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m95\u001b[39m)])\n\u001b[1;32m      2\u001b[0m Agentx \u001b[38;5;241m=\u001b[39m Agent()\n\u001b[0;32m----> 5\u001b[0m cost_per_episode, steps_per_episode, epsilon_per_episode, action_index_per_episode, qvalue_per_episode, state_per_episode \u001b[38;5;241m=\u001b[39m play(world, Agentx)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# using matplotlib for plotting episode in x-axis and cost in y-axis\u001b[39;00m\n\u001b[1;32m      9\u001b[0m fig1 \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFigure1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn [36], line 121\u001b[0m, in \u001b[0;36mplay\u001b[0;34m(world, Agent, alpha, gamma, episode, epsilon)\u001b[0m\n\u001b[1;32m    119\u001b[0m cost_per_step \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    120\u001b[0m state_per_step \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[43mworld\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepisode_break\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m     lastState \u001b[38;5;241m=\u001b[39m world\u001b[38;5;241m.\u001b[39mstate\n\u001b[1;32m    124\u001b[0m     state_per_step\u001b[38;5;241m.\u001b[39mappend(lastState)\n",
      "Cell \u001b[0;32mIn [36], line 69\u001b[0m, in \u001b[0;36mContinuous_gridWorld.episode_break\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mepisode_break\u001b[39m(\u001b[38;5;28mself\u001b[39m, state):\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mterminal_state:\n\u001b[0;32m---> 69\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;241m==\u001b[39m i:\n\u001b[1;32m     70\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocked_list:\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "world = Continuous_gridWorld([(50, 50), (60, 50), (70, 50), (90, 50), (60,65), (60, 75), (60, 85), (60, 95)])\n",
    "Agentx = Agent()\n",
    "\n",
    "\n",
    "cost_per_episode, steps_per_episode, epsilon_per_episode, action_index_per_episode, qvalue_per_episode, state_per_episode = play(world, Agentx)\n",
    "\n",
    "\n",
    "# using matplotlib for plotting episode in x-axis and cost in y-axis\n",
    "fig1 = plt.figure(\"Figure1\")\n",
    "plt.plot(cost_per_episode)\n",
    "plt.ylim(0, 150)\n",
    "plt.title(\"Cost per Episode\")\n",
    "fig2 = plt.figure(\"Figure2\")\n",
    "plt.plot(steps_per_episode)\n",
    "plt.ylim(0, 150)\n",
    "plt.title(\"Steps per Episode\")\n",
    "fig3 = plt.figure(\"Figure3\")\n",
    "plt.plot(epsilon_per_episode)\n",
    "plt.title(\"Epsilon per Episode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05364ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "hi\n"
     ]
    }
   ],
   "source": [
    "x = [1, 2, 3]\n",
    "y = [2, 9, 1]\n",
    "\n",
    "for i in x:\n",
    "    if i in y:\n",
    "        print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d967c70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
